{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZqLTbzdVcEJT"
      },
      "source": [
        "<div style=\"display: flex; align-items: center; gap: 40px;\">\n",
        "\n",
        "<img src=\"https://play-lh.googleusercontent.com/_O9p4Z4yucA2NLmZBu9mTJCuBwXeT9NcbtrDN6I8gKlkIPRySV0adOmbyipjSj9Gew\" width=\"138\">\n",
        "\n",
        "<img src=\"https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcQSeRdOo-WucXlITj0XdjTKYQch6QQk-ARyfA&s\" width=\"210\">\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "\n",
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/drive/1DMaBjL3euIOTAMvFH3l1CcTE3kHlYZ-0?usp=sharing)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "94UgaFNMb9c_"
      },
      "source": [
        "<div>\n",
        "  <h2>SUTRA by TWO Platforms </h2>\n",
        "  <p>SUTRA is a family of large multi-lingual language (LMLMs) models pioneered by Two Platforms. SUTRA’s dual-transformer approach extends the power of both MoE and Dense AI language model architectures, delivering cost-efficient multilingual capabilities for over 50+ languages. It powers scalable AI applications for conversation, search, and advanced reasoning, ensuring high-performance across diverse languages, domains and applications.</p>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KDTX4VK5GvQU"
      },
      "source": [
        "# AutoGen Agents With SUTRA\n",
        "\n",
        "This notebook demonstrates how to integrate Sutra, a powerful language model from Two AI, with AutoGen, a framework for building agent-based systems. We'll create multi-agent systems that leverage Sutra's capabilities for various tasks."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gVSJrGrbcldl"
      },
      "source": [
        "## Get Your API Keys\n",
        "\n",
        "Before you begin, make sure you have:\n",
        "\n",
        "1. A SUTRA API key (Get yours at [TWO AI's SUTRA API page](https://www.two.ai/sutra/api))\n",
        "2. Basic familiarity with Python and Jupyter notebooks\n",
        "\n",
        "This notebook is designed to run in Google Colab, so no local Python installation is required."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D4mpMcMHGvQa"
      },
      "source": [
        "## Setup\n",
        "\n",
        "First, let's install the required packages if they're not already installed."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qnxNlJnHGvQc",
        "outputId": "da53b562-00d3-4246-b95a-8f05b16ecd36"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m781.7/781.7 kB\u001b[0m \u001b[31m13.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.5/45.5 kB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m147.8/147.8 kB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip install -q pyautogen openai"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rAlfsK6RGvQh"
      },
      "source": [
        "## Import Libraries\n",
        "\n",
        "Now, let's import the necessary libraries for our AutoGen application."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H6P7VVrCGvQi"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import json\n",
        "import autogen\n",
        "from autogen import AssistantAgent, UserProxyAgent, config_list_from_json\n",
        "from google.colab import userdata\n",
        "\n",
        "\n",
        "# Set your API key for Two AI\n",
        "api_key = userdata.get(\"SUTRA_API_KEY\")  # Replace with your actual API key\n",
        "# os.environ[\"TWO_AI_API_KEY\"] = api_key  # Uncomment this line if you prefer to use environment variables"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QrXXIYh_GvQj"
      },
      "source": [
        "## Configure Sutra with AutoGen\n",
        "\n",
        "AutoGen supports custom LLM configurations, which we'll use to set up Sutra. We need to configure the API endpoint and model parameters."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IE8YFKsuGvQp"
      },
      "outputs": [],
      "source": [
        "# Create a configuration for Sutra\n",
        "sutra_config = {\n",
        "    \"model\": \"sutra-v2\",  # or \"sutra-r0\" for reasoning tasks\n",
        "    \"api_key\": api_key,\n",
        "    \"base_url\": \"https://api.two.ai/v2\",\n",
        "    \"api_type\": \"openai\",\n",
        "\n",
        "}\n",
        "\n",
        "# Create a configuration list for AutoGen\n",
        "config_list = [sutra_config]\n",
        "\n",
        "# Alternatively, you can save this configuration to a JSON file\n",
        "with open(\"sutra_config.json\", \"w\") as f:\n",
        "    json.dump({\"model_configs\": [sutra_config]}, f)\n",
        "\n",
        "# And then load it using AutoGen's utility function\n",
        "# config_list = config_list_from_json(\"sutra_config.json\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iEph68HoGvQs"
      },
      "source": [
        "## Create a Simple Conversational Agent\n",
        "\n",
        "Let's start by creating a simple conversational agent using Sutra and AutoGen."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SALRWnLYGvQt"
      },
      "outputs": [],
      "source": [
        "# Create an assistant agent powered by Sutra\n",
        "assistant = AssistantAgent(\n",
        "    name=\"sutra_assistant\",\n",
        "    system_message=\"You are a helpful assistant powered by Sutra. You provide concise, accurate, and helpful responses.\",\n",
        "    llm_config={\"config_list\": config_list}\n",
        ")\n",
        "\n",
        "# Create a user proxy agent\n",
        "user_proxy = UserProxyAgent(\n",
        "    name=\"user_proxy\",\n",
        "    human_input_mode=\"TERMINATE\",  # Set to \"ALWAYS\" if you want to provide input at each step\n",
        "    max_consecutive_auto_reply=0,  # Set to a higher number for more autonomous conversations\n",
        "    system_message=\"You are a human user having a conversation with an AI assistant.\"\n",
        ")\n",
        "\n",
        "# Start a conversation\n",
        "user_proxy.initiate_chat(\n",
        "    assistant,\n",
        "    message=\"Hello! Can you tell me about Sutra and its capabilities?\"\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Psvfewq4GvQw"
      },
      "source": [
        "## Create a Multi-Agent System\n",
        "\n",
        "Now, let's create a more complex multi-agent system with different roles and capabilities."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Xp6foV4eGvQx"
      },
      "outputs": [],
      "source": [
        "# Create a technical expert agent\n",
        "technical_expert = AssistantAgent(\n",
        "    name=\"technical_expert\",\n",
        "    system_message=\"\"\"You are a technical expert powered by Sutra. You specialize in providing technical information,\n",
        "    explaining concepts, and helping with code. Provide detailed and accurate technical explanations.\"\"\",\n",
        "    llm_config={\"config_list\": config_list}\n",
        ")\n",
        "\n",
        "# Create a creative writer agent\n",
        "creative_writer = AssistantAgent(\n",
        "    name=\"creative_writer\",\n",
        "    system_message=\"\"\"You are a creative writer powered by Sutra. You specialize in creative writing, storytelling,\n",
        "    and generating imaginative content. Be engaging and creative in your responses.\"\"\",\n",
        "    llm_config={\"config_list\": config_list}\n",
        ")\n",
        "\n",
        "# Create a research assistant agent\n",
        "research_assistant = AssistantAgent(\n",
        "    name=\"research_assistant\",\n",
        "    system_message=\"\"\"You are a research assistant powered by Sutra. You specialize in gathering information,\n",
        "    analyzing data, and providing well-researched answers. Be thorough and cite sources when possible.\"\"\",\n",
        "    llm_config={\"config_list\": config_list}\n",
        ")\n",
        "\n",
        "# Create a user proxy agent that can work with multiple agents\n",
        "user_proxy_multi = UserProxyAgent(\n",
        "    name=\"user_proxy\",\n",
        "    human_input_mode=\"TERMINATE\",\n",
        "    max_consecutive_auto_reply=0,\n",
        "    system_message=\"You are a human user interacting with multiple AI agents.\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jwzb2C-PGvQx"
      },
      "outputs": [],
      "source": [
        "# Function to interact with the appropriate agent based on the query\n",
        "def interact_with_agent(query):\n",
        "    # Simple keyword-based routing\n",
        "    if any(keyword in query.lower() for keyword in [\"code\", \"programming\", \"technical\", \"explain\", \"how to\"]):\n",
        "        print(\"Routing to Technical Expert...\\n\")\n",
        "        user_proxy_multi.initiate_chat(technical_expert, message=query)\n",
        "    elif any(keyword in query.lower() for keyword in [\"story\", \"creative\", \"imagine\", \"write\", \"fiction\"]):\n",
        "        print(\"Routing to Creative Writer...\\n\")\n",
        "        user_proxy_multi.initiate_chat(creative_writer, message=query)\n",
        "    elif any(keyword in query.lower() for keyword in [\"research\", \"information\", \"data\", \"analysis\", \"study\"]):\n",
        "        print(\"Routing to Research Assistant...\\n\")\n",
        "        user_proxy_multi.initiate_chat(research_assistant, message=query)\n",
        "    else:\n",
        "        # Default to technical expert if no clear routing\n",
        "        print(\"No clear routing, defaulting to Technical Expert...\\n\")\n",
        "        user_proxy_multi.initiate_chat(technical_expert, message=query)\n",
        "\n",
        "# Example queries\n",
        "queries = [\n",
        "    \"Explain how to use AutoGen with Sutra for building multi-agent systems.\",\n",
        "    \"Write a short story about AI agents collaborating to solve a complex problem.\",\n",
        "    \"Research the latest advancements in large language models and their applications.\"\n",
        "]\n",
        "\n",
        "# Process each query\n",
        "for query in queries:\n",
        "    print(f\"\\n\\nQUERY: {query}\\n\")\n",
        "    interact_with_agent(query)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1AyLhBmxGvQy"
      },
      "source": [
        "## Create a Group Chat with Multiple Agents\n",
        "\n",
        "AutoGen allows us to create group chats where multiple agents can collaborate to solve problems."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mc-2SYEXGvQy"
      },
      "outputs": [],
      "source": [
        "# Create a group chat manager\n",
        "groupchat = autogen.GroupChat(\n",
        "    agents=[user_proxy_multi, technical_expert, creative_writer, research_assistant],\n",
        "    messages=[],\n",
        "    max_round=10\n",
        ")\n",
        "manager = autogen.GroupChatManager(groupchat=groupchat, llm_config={\"config_list\": config_list})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uGiChBpVGvQy"
      },
      "outputs": [],
      "source": [
        "# Start a group chat\n",
        "user_proxy_multi.initiate_chat(\n",
        "    manager,\n",
        "    message=\"\"\"Let's collaborate on creating a new AI application that combines technical expertise,\n",
        "    creative storytelling, and research insights. What should we build and how should we approach it?\"\"\"\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vDUjd9SgGvQz"
      },
      "source": [
        "## Task-Solving Agent with Code Execution\n",
        "\n",
        "AutoGen supports agents that can execute code, which is useful for solving programming tasks."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s4k0Y1omGvQz"
      },
      "outputs": [],
      "source": [
        "# Create a coding assistant\n",
        "coding_assistant = AssistantAgent(\n",
        "    name=\"coding_assistant\",\n",
        "    system_message=\"\"\"You are a coding assistant powered by Sutra. You specialize in writing Python code to solve problems.\n",
        "    You provide clear explanations along with your code.\"\"\",\n",
        "    llm_config={\"config_list\": config_list}\n",
        ")\n",
        "\n",
        "# Create a user proxy agent that can execute code\n",
        "user_proxy_exec = UserProxyAgent(\n",
        "    name=\"user_proxy_exec\",\n",
        "    human_input_mode=\"TERMINATE\",\n",
        "    max_consecutive_auto_reply=10,  # Allow multiple auto-replies for code execution\n",
        "    system_message=\"You are a human user working with a coding assistant. You can execute Python code.\",\n",
        "    code_execution_config={\"work_dir\": \"coding_workspace\", \"use_docker\": False},  # Configure code execution\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tHgtuqnVGvQz"
      },
      "outputs": [],
      "source": [
        "# Start a conversation with a coding task\n",
        "user_proxy_exec.initiate_chat(\n",
        "    coding_assistant,\n",
        "    message=\"\"\"Write a Python function that generates the Fibonacci sequence up to n terms.\n",
        "    Then create a visualization of the sequence using matplotlib.\"\"\"\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-7pjYU-GGvQ2"
      },
      "source": [
        "## Conclusion\n",
        "\n",
        "In this notebook, we've demonstrated various ways to integrate Sutra with AutoGen for building agent-based systems:\n",
        "\n",
        "1. Simple conversational agents\n",
        "2. Multi-agent systems with specialized roles\n",
        "3. Group chats for collaborative problem-solving\n",
        "4. Task-solving agents with code execution\n",
        "\n",
        "\n",
        "These examples showcase the flexibility and power of combining Sutra's language capabilities with AutoGen's agent framework. You can extend these examples to create more sophisticated applications by:\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.16"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
